# ğŸ¯ ScrappingScan - API REST de Scraping de Mangas

API REST Node.js/Express pour scraper et gÃ©rer des mangas depuis AnimeSama.

## ğŸš€ DÃ©marrage Rapide

```bash
# 1. Installer PostgreSQL
brew install postgresql@16  # macOS
# Ou voir docs/QUICK_START.md pour Linux/Windows

# 2. CrÃ©er la base de donnÃ©es
psql postgres -c "CREATE DATABASE scrappingscan;"
psql postgres -c "CREATE USER scrappingscan WITH PASSWORD 'scrappingscan_password';"
psql postgres -c "GRANT ALL PRIVILEGES ON DATABASE scrappingscan TO scrappingscan;"

# 3. Installer les dÃ©pendances
npm install

# 4. Configurer l'environnement
cp .env.local .env

# 5. Appliquer les migrations
npm run prisma:migrate

# 6. Lancer l'API
npm run dev:local
```

âœ… API disponible sur **http://localhost:3000**

---

## âš¡ Commandes npm

### DÃ©veloppement

```bash
npm run dev:local      # Mode watch avec hot-reload âš¡
npm run start:local    # Mode production local
npm run build          # Compiler TypeScript
```

### Base de donnÃ©es

```bash
npm run prisma:migrate  # CrÃ©er/appliquer migrations
npm run prisma:studio   # Interface graphique DB
npm run prisma:generate # GÃ©nÃ©rer le client Prisma
```

---

## ğŸŒ Endpoints API

### Health & Info

```bash
GET  /health  # Status de l'API
```

### Mangas

```bash
GET  /api/mangas/:title        # RÃ©cupÃ©rer un manga par titre
GET  /api/mangas/site/:site    # Liste des mangas par site
GET  /api/mangas/:title/scans  # Liste des scans d'un manga
POST /api/mangas               # CrÃ©er un manga
POST /api/mangas/:title/scans  # Ajouter un scan
```

### Scraping

```bash
POST /api/scraping/add-manga      # Scraper un nouveau manga
POST /api/scraping/update-manga   # Mettre Ã  jour un manga
POST /api/scraping/update-all     # Mettre Ã  jour tous les mangas
```

**Exemple - Ajouter un manga :**

```bash
curl -X POST https://api.adrienbouteiller.fr/api/scraping/add-manga \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://anime-sama.eu/catalogue/haikyuu/scan/vf/",
    "site": "ANIME_SAMA"
  }'
```

**RÃ©ponse :**
```json
{
  "message": "Manga scraping started",
  "url": "https://anime-sama.eu/catalogue/haikyuu/scan/vf/"
}
```

> âš ï¸ Le scraping est **asynchrone**. L'API retourne immÃ©diatement (202 Accepted) et le scraping continue en arriÃ¨re-plan.

**GÃ©rer le scraping en cours :**

```bash
# Voir les logs en temps rÃ©el (mode direct/suivi)
pm2 logs scrappingscan-api

# Voir les derniÃ¨res lignes sans suivre
pm2 logs scrappingscan-api --lines 50 --nostream

# Filtrer les logs (erreurs uniquement)
pm2 logs scrappingscan-api --err

# Vider les logs
pm2 flush scrappingscan-api

# ArrÃªter le scraping en cours (redÃ©marre l'app)
pm2 restart scrappingscan-api

# Stopper complÃ¨tement l'app
pm2 stop scrappingscan-api

# RedÃ©marrer l'app
pm2 start scrappingscan-api

# Voir l'Ã©tat et la consommation
pm2 status
pm2 monit  # Interface interactive avec CPU/RAM
```

**Suivre le scraping en direct :**

```bash
# Ouvrir les logs en temps rÃ©el dans un terminal
pm2 logs scrappingscan-api

# Vous verrez dÃ©filer :
# [AnimeSamaScraper] â„¹ï¸  Scraping chapters from: https://...
# [AnimeSamaScraper] âœ… Found 409 chapters
# [ScrapingService] â„¹ï¸  Processing chapter 1: Chapitre 1
# [AnimeSamaScraper] â„¹ï¸  Scraping images for chapter: Chapitre 1
# [AnimeSamaScraper] âœ… Found 19 images
# [ScanRepositoryPrisma] âœ… Scan created: Chapter 1 - Chapitre 1

# Pour quitter : Ctrl+C
```

---

## ğŸ“š Documentation

- **[API Documentation (Swagger)](https://api.adrienbouteiller.fr/api-docs/)** - Documentation interactive des endpoints
- **[docs/QUICK_START.md](./docs/QUICK_START.md)** - Installation PostgreSQL + Workflow de dÃ©veloppement
- **[docs/DEPLOYMENT_SIMPLE.md](./docs/DEPLOYMENT_SIMPLE.md)** - Guide de dÃ©ploiement production

### API en Production

ğŸŒ **Production** : https://api.adrienbouteiller.fr  
ğŸ“– **Swagger UI** : https://api.adrienbouteiller.fr/api-docs/  
âœ… **Health Check** : https://api.adrienbouteiller.fr/health

---

## ğŸ› ï¸ Stack Technique

- **Runtime** : Node.js 20
- **Framework** : Express 5
- **Language** : TypeScript 5
- **Database** : PostgreSQL 16
- **ORM** : Prisma 6
- **Scraping** : Puppeteer + Stealth Plugin
- **Dev** : tsx (hot-reload)

---

## ğŸ“ Configuration

### Variables d'environnement (.env)

```env
DATABASE_URL="postgresql://scrappingscan:scrappingscan_password@localhost:5432/scrappingscan"
PORT=3000
NODE_ENV=development
CORS_ORIGIN=*
```

### Services

- **API** : http://localhost:3000
- **PostgreSQL** : localhost:5432
- **Prisma Studio** : http://localhost:5555

---

## ğŸ“Š Structure du Projet

```
ScrappingScan/
â”œâ”€â”€ README.md              â† Vous Ãªtes ici
â”œâ”€â”€ docs/                  â† Documentation
â”‚   â”œâ”€â”€ POSTGRESQL_INSTALL.md
â”‚   â”œâ”€â”€ QUICK_START.md
â”‚   â””â”€â”€ DEPLOYMENT_SIMPLE.md
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ server.ts          â† Point d'entrÃ©e
â”‚   â”œâ”€â”€ api/               â† Controllers & Routes
â”‚   â”œâ”€â”€ modules/           â† Manga & Scraping
â”‚   â”œâ”€â”€ core/              â† Database
â”‚   â””â”€â”€ shared/            â† Config & Utils
â”œâ”€â”€ prisma/
â”‚   â””â”€â”€ schema.prisma      â† SchÃ©ma DB
â”œâ”€â”€ .env.local             â† Config template
â”œâ”€â”€ package.json
â””â”€â”€ tsconfig.json
```

---

## ğŸ’¡ Workflow de DÃ©veloppement

1. **Lancer l'API** : `npm run dev:local`
2. **Modifier le code** : Les changements se rechargent automatiquement âš¡
3. **Tester** : `curl http://localhost:3000/health`
4. **Visualiser la DB** : `npm run prisma:studio`
5. **Commit** : `git commit -m "..." && git push`

---

## âš ï¸ Notes Importantes

### Scraping et Cloudflare

Le site anime-sama.eu utilise **Cloudflare**. Le scraping peut :

- â±ï¸ Prendre du temps (validation Cloudflare, ~5-10s par chapitre)
- âŒ Ã‰chouer si bloquÃ© par l'anti-bot
- ğŸ”„ NÃ©cessiter plusieurs tentatives
- ğŸš« ÃŠtre bloquÃ© en production (voir solutions ci-dessous)

**Le scraping est asynchrone** : L'endpoint retourne immÃ©diatement (202 Accepted) et continue en arriÃ¨re-plan.

**Solutions pour la production :**
1. **Scraper en local** et synchroniser la base de donnÃ©es vers la production
2. **Serveur dÃ©diÃ©** uniquement pour le scraping
3. **Services externes** (ScraperAPI, Bright Data, etc.)

### ArrÃªter un scraping en cours

Le scraping s'exÃ©cute en tÃ¢che de fond. Pour l'arrÃªter ou le surveiller :

```bash
# ğŸ”´ Voir les logs en TEMPS RÃ‰EL (Ctrl+C pour quitter)
pm2 logs scrappingscan-api

# ğŸ“Š Interface monitoring interactive (CPU/RAM)
pm2 monit

# ğŸ“ Voir les derniÃ¨res lignes sans suivre
pm2 logs scrappingscan-api --lines 100 --nostream

# ğŸ”„ RedÃ©marrer l'application (interrompt le scraping)
pm2 restart scrappingscan-api

# ğŸ›‘ Stopper complÃ¨tement
pm2 stop scrappingscan-api

# âœ… RedÃ©marrer aprÃ¨s un stop
pm2 start scrappingscan-api

# ğŸ“ˆ Voir l'Ã©tat et les stats
pm2 status
```

**Exemple de logs en direct :**

```
[AnimeSamaScraper] â„¹ï¸  Scraping chapters from: https://anime-sama.eu/...
[AnimeSamaScraper] âœ… Found 409 chapters
[ScrapingService] â„¹ï¸  Processing chapter 1: Chapitre 1
[AnimeSamaScraper] â„¹ï¸  Scraping images for chapter: Chapitre 1
[AnimeSamaScraper] âœ… Found 19 images
[ScanRepositoryPrisma] âœ… Scan created: Chapter 1 - Chapitre 1
[ScrapingService] â„¹ï¸  Processing chapter 2: Chapitre 2
...
```

### Performances

Puppeteer consomme beaucoup de RAM :

- **Minimum 2GB RAM** recommandÃ©
- Ne pas exÃ©cuter trop de scraping simultanÃ©s
- Le navigateur se ferme automatiquement aprÃ¨s chaque scraping
- Un manga de 400+ chapitres peut prendre plusieurs heures

---

## ğŸ‰ PrÃªt Ã  commencer ?

Suivez le [Guide de dÃ©marrage rapide](#-dÃ©marrage-rapide) ci-dessus !
